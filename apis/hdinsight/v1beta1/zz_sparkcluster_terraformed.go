//go:build (hdinsight || all) && !ignore_autogenerated

// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1beta1

import (
	"dario.cat/mergo"
	"github.com/pkg/errors"

	"github.com/crossplane/upjet/pkg/resource"
	"github.com/crossplane/upjet/pkg/resource/json"
)

// GetTerraformResourceType returns Terraform resource type for this SparkCluster
func (mg *SparkCluster) GetTerraformResourceType() string {
	return "azurerm_hdinsight_spark_cluster"
}

// GetConnectionDetailsMapping for this SparkCluster
func (tr *SparkCluster) GetConnectionDetailsMapping() map[string]string {
	return map[string]string{"extension[*].primary_key": "spec.forProvider.extension[*].primaryKeySecretRef", "gateway[*].password": "spec.forProvider.gateway[*].passwordSecretRef", "metastores[*].ambari[*].password": "spec.forProvider.metastores[*].ambari[*].passwordSecretRef", "metastores[*].hive[*].password": "spec.forProvider.metastores[*].hive[*].passwordSecretRef", "metastores[*].oozie[*].password": "spec.forProvider.metastores[*].oozie[*].passwordSecretRef", "monitor[*].primary_key": "spec.forProvider.monitor[*].primaryKeySecretRef", "roles[*].head_node[*].password": "spec.forProvider.roles[*].headNode[*].passwordSecretRef", "roles[*].worker_node[*].password": "spec.forProvider.roles[*].workerNode[*].passwordSecretRef", "roles[*].zookeeper_node[*].password": "spec.forProvider.roles[*].zookeeperNode[*].passwordSecretRef", "security_profile[*].domain_user_password": "spec.forProvider.securityProfile[*].domainUserPasswordSecretRef", "storage_account[*].storage_account_key": "spec.forProvider.storageAccount[*].storageAccountKeySecretRef"}
}

// GetObservation of this SparkCluster
func (tr *SparkCluster) GetObservation() (map[string]any, error) {
	o, err := json.TFParser.Marshal(tr.Status.AtProvider)
	if err != nil {
		return nil, err
	}
	base := map[string]any{}
	return base, json.TFParser.Unmarshal(o, &base)
}

// SetObservation for this SparkCluster
func (tr *SparkCluster) SetObservation(obs map[string]any) error {
	p, err := json.TFParser.Marshal(obs)
	if err != nil {
		return err
	}
	return json.TFParser.Unmarshal(p, &tr.Status.AtProvider)
}

// GetID returns ID of underlying Terraform resource of this SparkCluster
func (tr *SparkCluster) GetID() string {
	if tr.Status.AtProvider.ID == nil {
		return ""
	}
	return *tr.Status.AtProvider.ID
}

// GetParameters of this SparkCluster
func (tr *SparkCluster) GetParameters() (map[string]any, error) {
	p, err := json.TFParser.Marshal(tr.Spec.ForProvider)
	if err != nil {
		return nil, err
	}
	base := map[string]any{}
	return base, json.TFParser.Unmarshal(p, &base)
}

// SetParameters for this SparkCluster
func (tr *SparkCluster) SetParameters(params map[string]any) error {
	p, err := json.TFParser.Marshal(params)
	if err != nil {
		return err
	}
	return json.TFParser.Unmarshal(p, &tr.Spec.ForProvider)
}

// GetInitParameters of this SparkCluster
func (tr *SparkCluster) GetInitParameters() (map[string]any, error) {
	p, err := json.TFParser.Marshal(tr.Spec.InitProvider)
	if err != nil {
		return nil, err
	}
	base := map[string]any{}
	return base, json.TFParser.Unmarshal(p, &base)
}

// GetInitParameters of this SparkCluster
func (tr *SparkCluster) GetMergedParameters(shouldMergeInitProvider bool) (map[string]any, error) {
	params, err := tr.GetParameters()
	if err != nil {
		return nil, errors.Wrapf(err, "cannot get parameters for resource '%q'", tr.GetName())
	}
	if !shouldMergeInitProvider {
		return params, nil
	}

	initParams, err := tr.GetInitParameters()
	if err != nil {
		return nil, errors.Wrapf(err, "cannot get init parameters for resource '%q'", tr.GetName())
	}

	// Note(lsviben): mergo.WithSliceDeepCopy is needed to merge the
	// slices from the initProvider to forProvider. As it also sets
	// overwrite to true, we need to set it back to false, we don't
	// want to overwrite the forProvider fields with the initProvider
	// fields.
	err = mergo.Merge(&params, initParams, mergo.WithSliceDeepCopy, func(c *mergo.Config) {
		c.Overwrite = false
	})
	if err != nil {
		return nil, errors.Wrapf(err, "cannot merge spec.initProvider and spec.forProvider parameters for resource '%q'", tr.GetName())
	}

	return params, nil
}

// LateInitialize this SparkCluster using its observed tfState.
// returns True if there are any spec changes for the resource.
func (tr *SparkCluster) LateInitialize(attrs []byte) (bool, error) {
	params := &SparkClusterParameters{}
	if err := json.TFParser.Unmarshal(attrs, params); err != nil {
		return false, errors.Wrap(err, "failed to unmarshal Terraform state parameters for late-initialization")
	}
	opts := []resource.GenericLateInitializerOption{resource.WithZeroValueJSONOmitEmptyFilter(resource.CNameWildcard)}

	li := resource.NewGenericLateInitializer(opts...)
	return li.LateInitialize(&tr.Spec.ForProvider, params)
}

// GetTerraformSchemaVersion returns the associated Terraform schema version
func (tr *SparkCluster) GetTerraformSchemaVersion() int {
	return 0
}
